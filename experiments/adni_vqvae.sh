python3 /project/run_vqvae.py run \
  --training_subjects='/path/to/adni/training_samples.csv' \
  --validation_subjects='/path/to/adni/validation_samples.csv' \
  --load_nii_canonical=False \
  --project_directory='/results/' \
  --experiment_name='adni_vqvae' \
  --mode='training' \
  --device='ddp' \
  --distributed_port=29500 \
  --amp=True \
  --deterministic=False \
  --cuda_benchmark=True \
  --seed=4 \
  --epochs=451 \
  --learning_rate=0.000165 \
  --gamma=0.99999 \
  --log_every=1 \
  --checkpoint_every=1 \
  --checkpoint_loading_strict=True \
  --eval_every=1 \
  --loss='jukebox_perceptual' \
  --adversarial_component=True \
  --discriminator_network='baseline_discriminator' \
  --discriminator_learning_rate=5e-05 \
  --discriminator_loss='least_square' \
  --generator_loss='least_square' \
  --initial_factor_value=0 \
  --initial_factor_steps=25 \
  --max_factor_steps=50 \
  --max_factor_value=5 \
  --batch_size=8 \
  --normalize=True \
  --roi='((16,176), (16,240),(96,256))' \
  --eval_batch_size=8 \
  --num_workers=8 \
  --prefetch_factor=8 \
  --starting_epoch=0 \
  --network='baseline_vqvae' \
  --use_subpixel_conv=False \
  --use_slim_residual=True \
  --no_levels=4 \
  --downsample_parameters='((4,2,1,1),(4,2,1,1),(4,2,1,1),(4,2,1,1))' \
  --upsample_parameters='((4,2,1,0,1),(4,2,1,0,1),(4,2,1,0,1),(4,2,1,0,1))' \
  --no_res_layers=3 \
  --no_channels=256 \
  --codebook_type='ema' \
  --num_embeddings='(2048,)' \
  --embedding_dim='(32,)' \
  --decay='(0.5,)' \
  --commitment_cost='(0.25,)' \
  --max_decay_epochs=100 \
  --dropout=0.0 \
  --act='RELU'
